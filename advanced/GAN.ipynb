{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is : 1.11.0+cpu\n",
      "torchvision version is : 0.12.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "print(f'torch version is : {torch.__version__}')\n",
    "print(f'torchvision version is : {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Hyper-parameters\n",
    "epochs = 5\n",
    "latent_size = 64\n",
    "batch_size = 100\n",
    "hidden_size = 256\n",
    "image_size = 28 * 28\n",
    "sample_dir = 'samples'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating save images folder\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(os.path.join(os.getcwd(), sample_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the FashionMNIST Dataset \n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='../basics/mnist',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform, \n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='../basics/mnist',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloading pipelines\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the descriminator \n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1), # It means we have only 1 output class\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Define the generator\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert them to device type \n",
    "D = D.to(device=device)\n",
    "G = G.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss and optimizer\n",
    "loss = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x+1)/2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:57<00:00, 35.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Starting the training\n",
    "from torch import imag\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # Reshape the dataset \n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Generate the labels \n",
    "        real_labels = torch.ones(batch_size, 1).to(device=device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device=device)\n",
    "\n",
    "        # First train the discriminator\n",
    "        outputs = D(images)\n",
    "        outputs = outputs.to(device)\n",
    "        d_loss_real = loss(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        # Compute BCELoss using fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device) # fake image\n",
    "        fake_images = G(z) # Fake images outputs from generator\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = loss(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        # Backpropagation and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Let's generate the generator\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = loss(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step() \n",
    "\n",
    "        # Let's save the results and images \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3865130ac3a4a180d9f67584570fac47f03c39ebaa170ceee2ff80d68fa62cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
