{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forwad Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm version is  :4.64.0\n",
      "tqdm version is  :1.11.0+cpu\n",
      "numpy version is  :1.21.5\n",
      "tqdm version is  :0.11.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "sns.set()\n",
    "\n",
    "print(f'tqdm version is  :{tqdm.__version__}')\n",
    "print(f'tqdm version is  :{torch.__version__}')\n",
    "print(f'numpy version is  :{np.__version__}')\n",
    "print(f'tqdm version is  :{sns.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "train_dataset = FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_dataset = FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "hidden_size = 500\n",
    "input_size = 28 * 28\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data loading pipeline \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the model \n",
    "from turtle import forward\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    # Define the class attributes\n",
    "    def __init__(self, input_size = 784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Setting attributes values \n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=self.input_size, \n",
    "                            out_features=self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=self.hidden_size,\n",
    "                             out_features=self.num_classes)\n",
    "    \n",
    "    # Define forwars pass\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# initialize the model \n",
    "model = NeuralNet(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps are : 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:13<00:53, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is : 0, loss is : 0.6293003559112549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:26<00:40, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is : 1, loss is : 0.5525667071342468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:40<00:26, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is : 2, loss is : 0.5119879245758057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:53<00:13, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is : 3, loss is : 0.48824813961982727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:06<00:00, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is : 4, loss is : 0.4728589355945587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's deinfe the training loop\n",
    "total_steps = len(train_dataset)\n",
    "print(f'total steps are : {total_steps}')\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # We need to reshape the images \n",
    "        images = images.reshape(-1, input_size)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Let's define the forward loop\n",
    "        outputs = model(images)\n",
    "        l = loss(outputs, labels)\n",
    "\n",
    "        # Let's deifne the backpropagation and optimization \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch is : {epoch}, loss is : {l.item()}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81.72 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3865130ac3a4a180d9f67584570fac47f03c39ebaa170ceee2ff80d68fa62cc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
